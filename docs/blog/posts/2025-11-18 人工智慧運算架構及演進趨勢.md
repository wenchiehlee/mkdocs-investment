---
authors: [wenchiehlee]
date: 2025-11-18
categories:
  - AI
  - 演講
tags:
  - AI
  - 算力
  - AI運算架構
  - 七層模型
  - 演講筆記
title: 人工智慧運算架構及演進趨勢
comments: true
draft: true
description: 記錄梁伯嵩博士在陽交大資工的演講內容，整理AI計算架構七層模型與演進路線
Purpose: 演講重點整理，建立 AI 運算七層與演進理解
Audience: AI 工程/研究者、科技趨勢關注者
---

# 🧠 人工智慧運算架構及演進趨勢

## 概述

2025.11.18（二）在陽交大資工的演講中，聯發科資深處長梁伯嵩博士以「網路七層」為靈感，提出 **AI 計算架構七層模型**，用來解釋 AI 的演化路線：**單一模型變強 → 推理變強 → 多代理模型與實體世界互動**。本篇整理為演講筆記，重點放在各層的工程脈絡與演進趨勢。

!!! note "定位"
    這篇是演講重點整理，適合快速理解 AI 計算架構的「層次關係」與「演進方向」，不是完整技術白皮書。

## 講者介紹

- 聯發科資深處長，長年投入 AI 運算架構與新興技術研究。
- 每年在台大與交大開課，內容多為第一線觀察與主動學習累積（聽報告、追論文、線上課程等）。
- 演講對應同名 arXiv 論文：**AI Compute Architecture and Evolution Trends**。
  - 參考連結：https://arxiv.org/abs/2508.21394
  - 演講影片：https://www.youtube.com/watch?v=THmdqnjCiSA
  - 臉書貼文來源：https://www.facebook.com/liang.jun.wei.288513/posts/%E8%81%AF%E7%99%BC%E7%A7%91%E8%B3%87%E6%B7%B1%E8%99%95%E9%95%B7%E6%96%BC%E9%99%BD%E4%BA%A4%E5%A4%A7%E8%B3%87%E5%B7%A5%E7%9A%84%E4%B8%80%E5%A0%B4%E6%BC%94%E8%AC%9B%E4%B8%BB%E9%A1%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E9%81%8B%E7%AE%97%E6%9E%B6%E6%A7%8B%E5%8F%8A%E6%BC%94%E9%80%B2%E8%B6%A8%E5%8B%A2ai-compute-architecture-and-evolution-trends%E6%99%82%E9%96%932/25719821784280328/

## 動機：算力需求成長遠超硬體摩爾定律

- 2013 AlexNet → 2023 Gemini，十年 AI 運算需求成長約 **10^8**。
- 摩爾定律十年約 100 倍；限定 GPU 的進步約 10,000 倍。
- 剩餘差距主要靠 **Scale-Out** 補齊。

## AI 計算架構七層模型（概要）

| 層級 | 名稱 | 重點 | 主要焦點 |
|---|---|---|---|
| L1 | 實體層 | Scale-Up、晶片/節點設計 | Training |
| L2 | 連接層 | Scale-Out、機櫃/機房互聯 | Training |
| L3 | 神經網路層 | RLVR、模型推理與效率 | Inference |
| L4 | 情境層 | 提示詞範式與人機互動 | Inference |
| L5 | 代理層 | 單一 Agent 能力組裝 | Multi-Agent |
| L6 | 協調層 | 多 Agent 資源/任務調度 | Multi-Agent |
| L7 | 應用層 | 授權、SLA、服務連續性 | Multi-Agent |

## L1 實體層：Scale-Up 的極限與效益

**核心焦點：Training**

- **Compute Die**：受限光罩尺度（約 3cm x 3cm），只能在尺寸內塞更多電晶體。
- **Chip**：常見包含 2 個 Memory Die，左右服務 Compute Die。
- **Compute Node**：4 或 8 顆 Chip 兩兩互連，節點間也可透過網路串接。
- 衡量方式：**每秒算力（x 軸）** vs **每瓦算力（y 軸）**。
  - Scale-Up 同時提升 x/y。
  - 但 **每瓦提升速度比每秒慢 10 倍**，能效成為瓶頸。

## L2 連接層：Scale-Out 的代價與策略

**核心焦點：Training**

- **機櫃內互聯**：距離 < 1m，仍可用銅線。
- **跨機櫃互聯**：距離數米以上，開始使用光互聯以降功耗/延遲。
- **Scalable Unit**：8 個機櫃，每櫃 72 GPU。
- **16 個 Scalable Units**：總計 9,216 GPU，耗能約 19.2 MW。
- 衡量方式仍是 x/y：
  - Scale-Out 是 **用 y 換 x**。
  - 現實存在 Bubble/損耗，實際效能更低。
- 黃仁勳的兩句話：
  - **「想 Scale-Out，請先 Scale-Up。」**
  - **「關鍵在於減緩每瓦算力下降。」**

## L3 神經網路層：推理時代的算力需求

**核心焦點：Inference**

- **RLVR（可驗證獎勵的強化學習）**讓 Test-time 也要吃算力。
- 模型能力突破路線：
  - 2010–2017：視覺
  - 2017–2022：語言（Transformer）
  - 2022–2024：科學問題（LLM + CoT）
- **民主化 AI**：
  - 大 LLM（>100B）：雲端
  - 中 LLM（10B–100B）：地端伺服器
  - 小 LLM（<1B）：手機/IoT
- 兩條演化路線：
  - **模型更大 + 更長時間**
  - **模型更小 + 更長時間**
  - 前者進展可透過蒸餾/開源讓後者受益。
- 架構設計議題：Workload（MoE）、平行化（資料/層/Tensor）、記憶體（Compute in Memory）、使用者體驗（吐 token 延遲）。

## L4 情境層：從「程式」到「提示詞」

**核心焦點：Inference**

傳統計算機架構關注：

- Bit & Bytes、CPU、Program Counter、Sequential 執行

LLM 架構轉為：

- Token、GPU、Attention、自我優化

LLM 不只是生成文字，也能透過壓縮/轉換改善資訊密度（例如文字轉圖、解壓縮）。

## L5 代理層：一個 Agent 就是一個職能

**核心焦點：一群 AI**

- 一個 Agent = 白領技能（記憶 + 規劃 + 使用工具 + 行動執行）。
- 多 Agent 組裝可形成完整組織（航空公司、旅行社、旅館等）。
- 每個電子產品也可能是一個 Agent，建立 AI 生態系。

## L6 協調層：資源調度就是「AI 主管」

**核心焦點：一群 AI**

- 每個 Agent 像球員，管理者負責評估、選擇、調度。
- AI 資源管理類比企業 HR：優先順序、績效、資源配置。

## L7 應用層：服務連續性與授權

**核心焦點：一群 AI**

- 關注授權、合規與不中斷服務（SLA）。
- 核心在於把多 Agent 組合成可持續運行的系統。

## 總論：Physical AI 的下一步

- 目前 AI 仍像「罐中之腦」，缺乏真實世界經驗（磁力、電力、物理規則）。
- 模擬成本高，且容易被虛實混淆（魔術、魔法世界）。
- 讓 AI 直接面向現實世界，有機會反過來強化其知識體系與驗證能力。
- 科學典範的演進一直是 **從模型到現實驗證**：四元素 → 萬有引力 → 相對論。

## 總結

這場演講把 AI 運算架構拆成 7 層，清楚劃分了 **Training → Inference → Multi-Agent** 的演化邏輯。對工程與研究者來說，這個框架能快速定位瓶頸與投資重點；對一般讀者來說，也能理解 AI 為何必須同時追求 Scale-Up、Scale-Out 與多代理協作。

有問題歡迎留言討論，說不定講者會親自現身交流 🙌
